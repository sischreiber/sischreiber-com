<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>How Understanding Transformer Architecture Helps Craft Better LLM Prompts | Simon Schreiber | Product Management Consultant</title>
<meta name=keywords content><meta name=description content="It is 2025 and AI is well beyond the experimental phase. It is now embedded in the daily workflows of product teams. Language models assist with drafting OKRs, identifying gaps in strategy, screening interview responses, analyzing churn data and generating test scenarios from acceptance criteria. Most of these tasks are powered by large language models (LLMs).
What Happens During Prompting
When you type a prompt into ChatGPT or Claude, the model replies with something fluent and useful. But what actually happens inside? An LLM is a deep neural network trained on vast amounts of text. It generates responses by predicting one token at a time. This entire process runs on the Transformer architecture, the foundation behind models like GPT-4, Claude and Gemini."><meta name=author content="Simon"><link rel=canonical href=https://www.sischreiber.com/posts/llm/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://www.sischreiber.com/img/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://www.sischreiber.com/img/favicon.ico><link rel=icon type=image/png sizes=32x32 href=https://www.sischreiber.com/img/favicon.ico><link rel=apple-touch-icon href=https://www.sischreiber.com/img/favicon.ico><link rel=mask-icon href=https://www.sischreiber.com/img/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://www.sischreiber.com/posts/llm/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-YF40GW2FXK"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-YF40GW2FXK")</script><meta property="og:title" content="How Understanding Transformer Architecture Helps Craft Better LLM Prompts"><meta property="og:description" content="It is 2025 and AI is well beyond the experimental phase. It is now embedded in the daily workflows of product teams. Language models assist with drafting OKRs, identifying gaps in strategy, screening interview responses, analyzing churn data and generating test scenarios from acceptance criteria. Most of these tasks are powered by large language models (LLMs).
What Happens During Prompting
When you type a prompt into ChatGPT or Claude, the model replies with something fluent and useful. But what actually happens inside? An LLM is a deep neural network trained on vast amounts of text. It generates responses by predicting one token at a time. This entire process runs on the Transformer architecture, the foundation behind models like GPT-4, Claude and Gemini."><meta property="og:type" content="article"><meta property="og:url" content="https://www.sischreiber.com/posts/llm/"><meta property="og:image" content="https://www.sischreiber.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-06-14T00:00:00+00:00"><meta property="article:modified_time" content="2025-06-14T00:00:00+00:00"><meta property="og:site_name" content="Simon Schreiber"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.sischreiber.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="How Understanding Transformer Architecture Helps Craft Better LLM Prompts"><meta name=twitter:description content="It is 2025 and AI is well beyond the experimental phase. It is now embedded in the daily workflows of product teams. Language models assist with drafting OKRs, identifying gaps in strategy, screening interview responses, analyzing churn data and generating test scenarios from acceptance criteria. Most of these tasks are powered by large language models (LLMs).
What Happens During Prompting
When you type a prompt into ChatGPT or Claude, the model replies with something fluent and useful. But what actually happens inside? An LLM is a deep neural network trained on vast amounts of text. It generates responses by predicting one token at a time. This entire process runs on the Transformer architecture, the foundation behind models like GPT-4, Claude and Gemini."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://www.sischreiber.com/posts/"},{"@type":"ListItem","position":2,"name":"How Understanding Transformer Architecture Helps Craft Better LLM Prompts","item":"https://www.sischreiber.com/posts/llm/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"How Understanding Transformer Architecture Helps Craft Better LLM Prompts","name":"How Understanding Transformer Architecture Helps Craft Better LLM Prompts","description":"It is 2025 and AI is well beyond the experimental phase. It is now embedded in the daily workflows of product teams. Language models assist with drafting OKRs, identifying gaps in strategy, screening interview responses, analyzing churn data and generating test scenarios from acceptance criteria. Most of these tasks are powered by large language models (LLMs).\nWhat Happens During Prompting When you type a prompt into ChatGPT or Claude, the model replies with something fluent and useful. But what actually happens inside? An LLM is a deep neural network trained on vast amounts of text. It generates responses by predicting one token at a time. This entire process runs on the Transformer architecture, the foundation behind models like GPT-4, Claude and Gemini.\n","keywords":[],"articleBody":"It is 2025 and AI is well beyond the experimental phase. It is now embedded in the daily workflows of product teams. Language models assist with drafting OKRs, identifying gaps in strategy, screening interview responses, analyzing churn data and generating test scenarios from acceptance criteria. Most of these tasks are powered by large language models (LLMs).\nWhat Happens During Prompting When you type a prompt into ChatGPT or Claude, the model replies with something fluent and useful. But what actually happens inside? An LLM is a deep neural network trained on vast amounts of text. It generates responses by predicting one token at a time. This entire process runs on the Transformer architecture, the foundation behind models like GPT-4, Claude and Gemini.\nProcessing Language with a Transformer 1. Prompt Everything starts with an input prompt. It defines the task to be completed, such as outlining a product roadmap or generating product ideas. Before processing, the text must be converted into a numerical format.\n2. Tokenizer The first step after the prompt is submitted is tokenization. The input prompt is split into small chunks called tokens. For example, the phrase “machine learning” might become the tokens “machine” and “learning” or even smaller units depending on the model.\nEach token is then mapped to a numerical vector known as an embedding. This vector represents the token’s meaning in a form the model can work with.\n3. Transformer This is where the model starts to “think”. Not by understanding, but by comparing.\nThe input moves through a series of steps where the model figures out how each word relates to the others. It decides what to focus on and what to ignore. This weighing of relevance is called self attention and it is a key part of how the Transformer works. It allows the model to build a sense of meaning based on context.\nFor example “traffic” means something different next to “landing page” than it does next to “server load”. The model works by spotting statistical patterns it has seen during training and using them to decide what fits best in the current context.\n4. Output After processing the input, the model predicts what comes next. It scores all possible tokens based on everything generated so far, turns those scores into probabilities and selects the most likely next token.\nThat token is added to the output and the process repeats until the model reaches a limit or completes the response.\nLLMs are non deterministic, so the same prompt can produce different outputs. This flexibility is useful, but it makes careful prompting even more important.\nWhy Model Architecture Matters for Prompting Context Is Evaluated, Not Understood Transformer models use self attention to decide which words in the prompt matter most. Since the whole prompt is processed at once, structure becomes important. Key information should appear early and unnecessary repetition should be avoided.\nLanguage Is Predicted, Not Interpreted Think of LLMs as probability engines that complete text based on patterns, not as humans that understand meaning. LLMs generate output based on learned patterns from training data. They do not understand text but estimate what is likely to follow. Prompts must therefore be precise and well structured.\nIntentionally Use Chain-of-Thought Prompting Encouraging the LLM to reason step by step leads to better answers. This approach reflects chain-of-thought prompting, which aligns well with how the model works.\nFinal Thoughts A basic understanding of Transformer architecture is not essential for using LLMs, but it improves both prompting strategy and output.\n","wordCount":"583","inLanguage":"en","image":"https://www.sischreiber.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2025-06-14T00:00:00Z","dateModified":"2025-06-14T00:00:00Z","author":{"@type":"Person","name":"Simon"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.sischreiber.com/posts/llm/"},"publisher":{"@type":"Organization","name":"Simon Schreiber | Product Management Consultant","logo":{"@type":"ImageObject","url":"https://www.sischreiber.com/img/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://www.sischreiber.com/ accesskey=h title="Simon Schreiber (Alt + H)"><img src=https://www.sischreiber.com/apple-touch-icon.png alt aria-label=logo height=35>Simon Schreiber</a><div class=logo-switches></div></div><ul id=menu><li><a href=https://www.sischreiber.com/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://www.sischreiber.com/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://www.sischreiber.com/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">How Understanding Transformer Architecture Helps Craft Better LLM Prompts</h1><div class=post-meta><span title='2025-06-14 00:00:00 +0000 UTC'>June 14, 2025</span></div></header><div class=post-content><p>It is 2025 and AI is well beyond the experimental phase. It is now embedded in the daily workflows of product teams. Language models assist with drafting OKRs, identifying gaps in strategy, screening interview responses, analyzing churn data and generating test scenarios from acceptance criteria. Most of these tasks are powered by large language models (LLMs).</p><h2 id=what-happens-during-prompting>What Happens During Prompting<a hidden class=anchor aria-hidden=true href=#what-happens-during-prompting>#</a></h2><p>When you type a prompt into ChatGPT or Claude, the model replies with something fluent and useful. But what actually happens inside? An LLM is a deep neural network trained on vast amounts of text. It generates responses by predicting one token at a time. This entire process runs on the Transformer architecture, the foundation behind models like GPT-4, Claude and Gemini.</p><h2 id=processing-language-with-a-transformer>Processing Language with a Transformer<a hidden class=anchor aria-hidden=true href=#processing-language-with-a-transformer>#</a></h2><p><img loading=lazy src=/img/llm.png alt="LLM Transformer Architecture"></p><h3 id=1-prompt>1. Prompt<a hidden class=anchor aria-hidden=true href=#1-prompt>#</a></h3><p>Everything starts with an input prompt. It defines the task to be completed, such as outlining a product roadmap or generating product ideas. Before processing, the text must be converted into a numerical format.</p><h3 id=2-tokenizer>2. Tokenizer<a hidden class=anchor aria-hidden=true href=#2-tokenizer>#</a></h3><p>The first step after the prompt is submitted is tokenization. The input prompt is split into small chunks called tokens. For example, the phrase &ldquo;machine learning&rdquo; might become the tokens &ldquo;machine&rdquo; and &ldquo;learning&rdquo; or even smaller units depending on the model.</p><p>Each token is then mapped to a numerical vector known as an embedding. This vector represents the token’s meaning in a form the model can work with.</p><h3 id=3-transformer>3. Transformer<a hidden class=anchor aria-hidden=true href=#3-transformer>#</a></h3><p>This is where the model starts to &ldquo;think&rdquo;. Not by understanding, but by comparing.</p><p>The input moves through a series of steps where the model figures out how each word relates to the others. It decides what to focus on and what to ignore. This weighing of relevance is called self attention and it is a key part of how the Transformer works. It allows the model to build a sense of meaning based on context.</p><p>For example &ldquo;traffic&rdquo; means something different next to &ldquo;landing page&rdquo; than it does next to &ldquo;server load&rdquo;. The model works by spotting statistical patterns it has seen during training and using them to decide what fits best in the current context.</p><h3 id=4-output>4. Output<a hidden class=anchor aria-hidden=true href=#4-output>#</a></h3><p>After processing the input, the model predicts what comes next. It scores all possible tokens based on everything generated so far, turns those scores into probabilities and selects the most likely next token.</p><p>That token is added to the output and the process repeats until the model reaches a limit or completes the response.</p><p>LLMs are non deterministic, so the same prompt can produce different outputs. This flexibility is useful, but it makes careful prompting even more important.</p><h2 id=why-model-architecture-matters-for-prompting>Why Model Architecture Matters for Prompting<a hidden class=anchor aria-hidden=true href=#why-model-architecture-matters-for-prompting>#</a></h2><h3 id=context-is-evaluated-not-understood>Context Is Evaluated, Not Understood<a hidden class=anchor aria-hidden=true href=#context-is-evaluated-not-understood>#</a></h3><p>Transformer models use self attention to decide which words in the prompt matter most. Since the whole prompt is processed at once, structure becomes important. Key information should appear early and unnecessary repetition should be avoided.</p><h3 id=language-is-predicted-not-interpreted>Language Is Predicted, Not Interpreted<a hidden class=anchor aria-hidden=true href=#language-is-predicted-not-interpreted>#</a></h3><p>Think of LLMs as probability engines that complete text based on patterns, not as humans that understand meaning. LLMs generate output based on learned patterns from training data. They do not understand text but estimate what is likely to follow. Prompts must therefore be precise and well structured.</p><h3 id=intentionally-use-chain-of-thought-prompting>Intentionally Use Chain-of-Thought Prompting<a hidden class=anchor aria-hidden=true href=#intentionally-use-chain-of-thought-prompting>#</a></h3><p>Encouraging the LLM to reason step by step leads to better answers. This approach reflects chain-of-thought prompting, which aligns well with how the model works.</p><h2 id=final-thoughts>Final Thoughts<a hidden class=anchor aria-hidden=true href=#final-thoughts>#</a></h2><p>A basic understanding of Transformer architecture is not essential for using LLMs, but it improves both prompting strategy and output.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 Simon Schreiber · <a href=/imprint/>Imprint</a> · <a href=/data/>Data</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script></body></html>